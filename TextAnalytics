#Read file
test1 <- read.csv(file.choose(),header=T)
str(test1)

# Text Parsing and filtering
library(tm)
corpus <- Corpus(VectorSource(test1$TweetTextSize))
inspect(corpus[1:10])

corpus <- tm_map(corpus, tolower)
inspect(corpus[1:10])

corpus <- tm_map(corpus, removePunctuation)
inspect(corpus[1:10])

corpus <- tm_map(corpus, removeNumbers)
inspect(corpus[1:10])

cleanset <- tm_map(corpus, removeWords, stopwords('English'))
inspect(corpus[1:10])

cleanset <- tm_map(cleanset, removeWords, c('\t','\n'))
inspect(corpus[1:10])

cleanset <- tm_map(cleanset, stripWhitespace)
inspect(corpus[1:10])

# Text transformation
tdm <- TermDocumentMatrix(cleanset)
tdm
tdm <- as.matrix(tdm)
tdm[1:150, 1:150]

v <- sort(rowSums(tdm), decreasing = TRUE)
d <- data.frame(word= names(v), freq = v)
head(d,10)

install.packages("wordcloud")
library(wordcloud)

set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1, max.words = 250, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"))

#Text Mining
install.packages("factoextra")
library(factoextra)
install.packages("rattle")
library(rattle)
install.packages("fpc")
library(fpc)
install.packages("flexclust")
library(flexclust)
install.packages("dendextend")
library(dendextend)

get_clust_tendency(tdm,n=100)

distMatrix <- dist(tdm, method = 'euclidean')
head(distMatrix)

dendo <- hclust(distMatrix, method = "ward.D")
plot(dendo)
